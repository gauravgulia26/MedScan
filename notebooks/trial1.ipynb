{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import streamlit as st\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = PyPDFLoader(\"/home/skynet/Documents/Gen_ai/med_scan/data/raw/WM17S.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Cleans a single text by removing common escape sequences, unnecessary characters, and empty elements.\"\"\"\n",
    "\n",
    "    # Remove common escape sequences (adjust as needed)\n",
    "    cleaned_text = re.sub(\n",
    "        r\"[\\x00-\\x1F\\x7F]\", \" \", text\n",
    "    )  # Removes control characters and replaces them with spaces\n",
    "    cleaned_text = re.sub(\n",
    "        r\"\\u200b\", \" \", cleaned_text\n",
    "    )  # Removes zero-width space and replaces it with a space\n",
    "\n",
    "    # Remove excessive whitespace\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text)\n",
    "\n",
    "    # Remove empty strings\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty pages\n",
    "# doc = [document for document in data if document.page_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = clean_text(text.split(\" \"))\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter, PdfReader\n",
    "\n",
    "pdf_reader = PdfReader(\"/home/skynet/Documents/Gen_ai/med_scan/data/raw/WM17S.pdf\")\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=40).split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrct_embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=os.getenv(\"HUGGINGFACE_APIKEY\"),\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "\n",
    "extrct_model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    max_tokens=7000,\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    "    model_kwargs={\"top_p\": 0.5},\n",
    "    api_key=os.getenv(\"GROQ_API_KEY_EXTRCT\"),\n",
    ")\n",
    "summ_model = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    max_tokens=7000,\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    "    model_kwargs={\"top_p\": 0.5},\n",
    "    api_key=os.getenv(\"GROQ_API_KEY_SUMM\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrct_db = FAISS.from_texts(corpus, extrct_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrct_db = extrct_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Task: Write a concise, detailed, and extensive summary of the following medical report.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. **Understand the Report:** Carefully read the medical report to grasp its key points, findings, and recommendations.\n",
    "2. **Summarize Key Points:** Concisely summarize the main findings, diagnoses, procedures, treatment recommendations, and outcomes.\n",
    "3. **Provide Insights:** Offer insights into potential implications, related conditions, recommended follow-up actions, and alternative treatment options.\n",
    "4. **Generate Questions:** Ask relevant questions that could help clarify the report's content, suggest further investigation, or address potential concerns.\n",
    "5. **Use Plain Language:** Explain complex medical terms or concepts in a clear and understandable way.\n",
    "6. **Avoid Medical Advice:** Refrain from providing medical advice or diagnoses. Always refer users to consult with a healthcare professional.\n",
    "7. **Find Values:** Summarize relevant values, such as lab results, vital signs, and measurements.\n",
    "8. **Include Patient Information:** Provide general patient information, including age and gender (without personally identifiable details).\n",
    "9. **Address Patient Concerns:** Summarize any patient concerns or questions and the corresponding responses if mentioned.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- **Focus on Relevance:** Ensure your responses are directly related to the content of the medical report.\n",
    "- **Be Objective:** Avoid personal opinions or biases in your analysis.\n",
    "- **Provide Clear Explanations:** Use simple language and avoid jargon.\n",
    "- **Be Respectful:** Treat the medical information with sensitivity and respect.\n",
    "\n",
    "The medical report is enclosed below:\n",
    "{context}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrct_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Task: Answer the user's queries based on the provided summary and the original Medical Report.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. **Understand the Summary:** Carefully read the summary to grasp its key points.\n",
    "2. **Reference the PDF:** Use the original PDF to verify and supplement the information in the summary.\n",
    "3. **Provide Comprehensive Answers:** Combine the information from both the summary and the PDF to provide accurate and informative responses.\n",
    "4. **Be Objective:** Avoid personal opinions or biases in your responses.\n",
    "5. **Be Accurate:** Verify the information in your responses using both sources.\n",
    "6. **Be Professional:** Maintain a professional tone and approach in your responses.\n",
    "7. **Be Respectful:** Treat the medical information with sensitivity and respect.\n",
    "8. **Provide Context:** Your answers should contain the section of the report the information is derived from.\n",
    "9. **Clarity and Detail:** Provide clear and detailed information to answer the query comprehensively.\n",
    "10. **Use Subheadings:** Organize your answers with subheadings to enhance readability.\n",
    "11. **Avoid Medical Advice:** Refrain from providing medical advice or diagnoses. Always refer users to consult with a healthcare professional.\n",
    "12. **Stay on Topic:** Always stay relevant to the query and avoid out-of-context or out-of-scope answers.\n",
    "13. **Greeting Style:** Start with a greeting, then provide the answer in a detailed manner.\n",
    "14. Comments: Your answer should also contain final comments about the query.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "- **Focus on Relevance:** Ensure your responses are directly related to the query and the summary/Medical Report.\n",
    "- **Be Clear and Detailed:** Explain your answers in an understandable manner with sufficient detail.\n",
    "- **Provide References:** Always reference the original data to support your answers.\n",
    "- **Respect Privacy:** Maintain the privacy of the user and the data at all times.\n",
    "\n",
    "Your context is as follows:\n",
    "<context>\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Original PDF:\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ_chain = summ_prompt | summ_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = summ_chain.invoke({\"context\": corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summ.txt\", \"w\") as f:\n",
    "    f.write(re.sub(r\"\\*\", \"\", result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrct_chain = create_stuff_documents_chain(extrct_model, extrct_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(extrct_db, extrct_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = retrieval_chain.invoke(\n",
    "    {\n",
    "        \"input\": \"What is the status of patient's lipid profile?\",\n",
    "        \"summary\": result,\n",
    "    }\n",
    ")[\"answer\"]\n",
    "\n",
    "with open(\"answer.txt\", \"w\") as f:\n",
    "    f.write(re.sub(r\"\\*\", \"\", answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geetagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
